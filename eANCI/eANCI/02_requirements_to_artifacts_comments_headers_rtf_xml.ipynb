{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Get the actual project root by going up to the main project directory\n",
    "notebook_path = Path.cwd()  # Current working directory (notebook location)\n",
    "project_root = notebook_path.parent.parent.parent  # Go up 3 levels to reach project root\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "from thesis_sentence_transformer.logger import setup_logging, handle_exception, DebugTimer\n",
    "\n",
    "logger = setup_logging(\"requirements_processor\")\n",
    "\n",
    "def sanitize_content(content):\n",
    "    \"\"\"\n",
    "    Sanitize content to ensure XML/JSON compatibility.\n",
    "    Replace or remove problematic characters while preserving meaningful whitespace.\n",
    "    \"\"\"\n",
    "    logger.debug(\"Sanitizing content\")\n",
    "    \n",
    "    # Define the XML 1.0 specification valid characters\n",
    "    # Valid ranges are:\n",
    "    # tab, newline, carriage return (0x9, 0xA, 0xD)\n",
    "    # ASCII characters (0x20-0x7E)\n",
    "    # Extended ASCII and Unicode (0x7F-0xFFFD)\n",
    "    # Excluding surrogate blocks (0xFDD0-0xFDEF)\n",
    "    \n",
    "    # First, replace common problematic characters\n",
    "    replacements = {\n",
    "        '\\u2018': \"'\",  # Left single quote\n",
    "        '\\u2019': \"'\",  # Right single quote\n",
    "        '\\u201C': '\"',  # Left double quote\n",
    "        '\\u201D': '\"',  # Right double quote\n",
    "        '\\u2013': '-',  # En dash\n",
    "        '\\u2014': '--', # Em dash\n",
    "        '\\u2026': '...' # Ellipsis\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        content = content.replace(old, new)\n",
    "    \n",
    "    # Function to check if a character is valid XML\n",
    "    def is_valid_xml_char(char):\n",
    "        codepoint = ord(char)\n",
    "        return (\n",
    "            codepoint == 0x9 or\n",
    "            codepoint == 0xA or\n",
    "            codepoint == 0xD or\n",
    "            (0x20 <= codepoint <= 0x7E) or\n",
    "            (0x7F <= codepoint <= 0xFFFD and not (0xFDD0 <= codepoint <= 0xFDEF))\n",
    "        )\n",
    "    \n",
    "    # Replace invalid characters with space\n",
    "    sanitized = ''.join(char if is_valid_xml_char(char) else ' ' for char in content)\n",
    "    \n",
    "    # Remove multiple spaces while preserving newlines\n",
    "    sanitized = re.sub(r' +', ' ', sanitized)\n",
    "    sanitized = re.sub(r'\\n +', '\\n', sanitized)\n",
    "    \n",
    "    # Clean up empty lines while preserving paragraph structure\n",
    "    sanitized = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', sanitized)\n",
    "    \n",
    "    logger.debug(\"Content sanitization completed\")\n",
    "    return sanitized.strip()\n",
    "\n",
    "def create_xml_structure(collection_id, name, description):\n",
    "    \"\"\"Create the basic XML structure for artifacts collection.\"\"\"\n",
    "    logger.debug(f\"Creating XML structure for collection: {collection_id}\")\n",
    "    \n",
    "    root = ET.Element(\"artifacts_collection\")\n",
    "    \n",
    "    # Add collection info\n",
    "    collection_info = ET.SubElement(root, \"collection_info\")\n",
    "    id_elem = ET.SubElement(collection_info, \"id\")\n",
    "    id_elem.text = collection_id\n",
    "    name_elem = ET.SubElement(collection_info, \"name\")\n",
    "    name_elem.text = name\n",
    "    version_elem = ET.SubElement(collection_info, \"version\")\n",
    "    version_elem.text = \"1.1\"\n",
    "    desc_elem = ET.SubElement(collection_info, \"description\")\n",
    "    desc_elem.text = description\n",
    "    \n",
    "    # Add artifacts container\n",
    "    artifacts = ET.SubElement(root, \"artifacts\")\n",
    "    \n",
    "    return root\n",
    "\n",
    "@handle_exception \n",
    "def extract_java_comments(content):\n",
    "    \"\"\"\n",
    "    Extract comments and structure from Java-like content\n",
    "    \n",
    "    Args:\n",
    "        content: String containing Java code\n",
    "    Returns:\n",
    "        String containing extracted comments and structure\n",
    "    \"\"\"\n",
    "    timer = DebugTimer(\"java_comment_extraction\", logger)\n",
    "    logger.debug(\"Starting Java comment extraction\")\n",
    "\n",
    "    # Initialize output\n",
    "    extracted_content = []\n",
    "    \n",
    "    # Track position in content\n",
    "    pos = 0\n",
    "    content_length = len(content)\n",
    "    logger.debug(f\"Processing content of length: {content_length}\")\n",
    "    \n",
    "    while pos < content_length:\n",
    "        timer.checkpoint(f\"Processing position {pos}\")\n",
    "        \n",
    "        # Look for comment markers\n",
    "        block_comment_start = content.find(\"/**\", pos)\n",
    "        line_comment_start = content.find(\"//\", pos)\n",
    "        \n",
    "        logger.debug(f\"Found block comment at: {block_comment_start}, line comment at: {line_comment_start}\")\n",
    "        \n",
    "        # No more comments found\n",
    "        if block_comment_start == -1 and line_comment_start == -1:\n",
    "            logger.debug(\"No more comments found, breaking loop\")\n",
    "            break\n",
    "            \n",
    "        # Process block comment\n",
    "        if block_comment_start != -1 and (line_comment_start == -1 or block_comment_start < line_comment_start):\n",
    "            logger.debug(f\"Processing block comment at position {block_comment_start}\")\n",
    "            block_comment_end = content.find(\"*/\", block_comment_start)\n",
    "            \n",
    "            if block_comment_end == -1:\n",
    "                logger.warning(\"Unclosed block comment found, breaking\")\n",
    "                break\n",
    "                \n",
    "            comment = content[block_comment_start:block_comment_end + 2]\n",
    "            extracted_content.append(comment)\n",
    "            pos = block_comment_end + 2\n",
    "            logger.debug(f\"Advanced position to: {pos} after block comment\")\n",
    "            \n",
    "        # Process line comment  \n",
    "        elif line_comment_start != -1:\n",
    "            logger.debug(f\"Processing line comment at position {line_comment_start}\")\n",
    "            line_end = content.find(\"\\n\", line_comment_start)\n",
    "            \n",
    "            if line_end == -1:\n",
    "                line_end = content_length\n",
    "                \n",
    "            comment = content[line_comment_start:line_end]\n",
    "            extracted_content.append(comment)\n",
    "            pos = line_end + 1\n",
    "            logger.debug(f\"Advanced position to: {pos} after line comment\")\n",
    "            \n",
    "        # Failsafe - if position hasn't advanced\n",
    "        if pos <= content_length and pos == block_comment_start:\n",
    "            logger.warning(f\"Position not advancing at {pos}, forcing advancement\")\n",
    "            pos += 1\n",
    "            \n",
    "        # Additional safety check\n",
    "        if pos > content_length:\n",
    "            logger.warning(\"Position exceeded content length, breaking\")\n",
    "            break\n",
    "            \n",
    "    timer.checkpoint(\"Finished comment extraction\")\n",
    "    result = \"\\n\".join(extracted_content)\n",
    "    timer.end()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def strip_rtf(content):\n",
    "    \"\"\"\n",
    "    Strip RTF formatting from text while preserving the actual content.\n",
    "    \n",
    "    Args:\n",
    "        content: String potentially containing RTF formatting\n",
    "        \n",
    "    Returns:\n",
    "        Plain text with RTF formatting removed\n",
    "    \"\"\"\n",
    "    logger.debug(\"Stripping RTF formatting\")\n",
    "    \n",
    "    # Check if content appears to be RTF\n",
    "    if not content.startswith('{\\\\rtf'):\n",
    "        return content\n",
    "        \n",
    "    # Remove RTF control words and groups\n",
    "    def strip_rtf_controls(text):\n",
    "        # Remove RTF headers and groups\n",
    "        text = re.sub(r'^{\\\\rtf[^}]*}', '', text)\n",
    "        # Remove other RTF groups\n",
    "        text = re.sub(r'{[^{}]*}', '', text)\n",
    "        # Remove RTF control words (starting with backslash)\n",
    "        text = re.sub(r'\\\\[a-z]+[-]?[0-9]*\\s?', '', text)\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'\\\\\\~|\\\\\\-|\\\\\\||\\\\\\:|\\\\\\<|\\\\\\>|\\\\\\{|\\\\\\}|\\\\\\'[0-9a-f]{2}', '', text)\n",
    "        return text\n",
    "    \n",
    "    # Strip RTF formatting\n",
    "    plain_text = strip_rtf_controls(content)\n",
    "    \n",
    "    # Clean up the resulting text\n",
    "    plain_text = re.sub(r'\\s+', ' ', plain_text)  # Normalize whitespace\n",
    "    plain_text = plain_text.strip()\n",
    "    \n",
    "    logger.debug(\"RTF formatting stripped successfully\")\n",
    "    return plain_text\n",
    "\n",
    "def process_requirement_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single requirement file and extract its content.\n",
    "    For Java-like content (in CC directory), only extract comments.\n",
    "    For RTF content, strip the formatting.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the requirement file\n",
    "        \n",
    "    Returns:\n",
    "        Sanitized content from the file\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Processing requirement file: {filepath}\")\n",
    "    \n",
    "    # First try UTF-8 with error handling\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as file:\n",
    "            content = file.read().strip()\n",
    "            if '\\ufffd' in content:  # Replacement character indicating encoding issues\n",
    "                raise UnicodeDecodeError('utf-8', b'', 0, 1, 'invalid start byte')\n",
    "            \n",
    "            # Check if this is likely Java code\n",
    "            java_indicators = ['package ', 'import ', 'public class', 'private class', 'protected class']\n",
    "            is_java = any(indicator in content for indicator in java_indicators)\n",
    "            \n",
    "            if is_java:\n",
    "                logger.debug(f\"Detected Java-like content in {filepath}\")\n",
    "                content = extract_java_comments(content)\n",
    "            else:\n",
    "                # Check for and strip RTF formatting\n",
    "                content = strip_rtf(content)\n",
    "            \n",
    "            return sanitize_content(content)\n",
    "            \n",
    "    except UnicodeDecodeError:\n",
    "        # Only log warning once per directory\n",
    "        dir_path = os.path.dirname(filepath)\n",
    "        if not hasattr(process_requirement_file, '_warned_dirs'):\n",
    "            process_requirement_file._warned_dirs = set()\n",
    "        if dir_path not in process_requirement_file._warned_dirs:\n",
    "            logger.warning(f\"Files in {dir_path} appear to use latin-1 encoding instead of UTF-8\")\n",
    "            process_requirement_file._warned_dirs.add(dir_path)\n",
    "            \n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='latin-1') as file:\n",
    "                content = file.read().strip()\n",
    "                \n",
    "                # Check for Java content with latin-1 encoding\n",
    "                java_indicators = ['package ', 'import ', 'public class', 'private class', 'protected class']\n",
    "                is_java = any(indicator in content for indicator in java_indicators)\n",
    "                \n",
    "                if is_java:\n",
    "                    logger.debug(f\"Detected Java-like content in {filepath}\")\n",
    "                    content = extract_java_comments(content)\n",
    "                else:\n",
    "                    # Check for and strip RTF formatting\n",
    "                    content = strip_rtf(content)\n",
    "                    \n",
    "                return sanitize_content(content)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file {filepath} with latin-1 encoding: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {filepath}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def add_artifact(artifacts_elem, req_id, content):\n",
    "    \"\"\"Add an artifact to the artifacts element.\"\"\"\n",
    "    logger.debug(f\"Adding artifact with ID: {req_id}\")\n",
    "    \n",
    "    try:\n",
    "        artifact = ET.SubElement(artifacts_elem, \"artifact\")\n",
    "        \n",
    "        id_elem = ET.SubElement(artifact, \"id\")\n",
    "        id_elem.text = req_id\n",
    "        \n",
    "        content_elem = ET.SubElement(artifact, \"content\")\n",
    "        content_elem.text = content\n",
    "        \n",
    "        parent_id = ET.SubElement(artifact, \"parent_id\")\n",
    "        \n",
    "        logger.debug(f\"Successfully added artifact: {req_id}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error adding artifact {req_id}: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_xml(xml_string):\n",
    "    \"\"\"Validate that the XML is well-formed.\"\"\"\n",
    "    try:\n",
    "        ET.fromstring(xml_string)\n",
    "        return True\n",
    "    except ET.ParseError as e:\n",
    "        logger.error(f\"XML validation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def prettify_xml(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\"\"\"\n",
    "    rough_string = ET.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    # Skip the XML declaration since we'll add it manually\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"  \")\n",
    "    # Remove the first line containing the XML declaration\n",
    "    return '\\n'.join(pretty_xml.split('\\n')[1:])\n",
    "\n",
    "def extract_requirement_id(filename, prefix):\n",
    "    \"\"\"\n",
    "    Extract the requirement ID from filename and add appropriate prefix.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The filename to process (e.g. 'EA140.txt' or 'EA1.txt')\n",
    "        prefix (str): The prefix to add ('UC' or 'CC')\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted ID (e.g. 'UC140' or 'CC1')\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Extracting requirement ID from filename: {filename} with prefix: {prefix}\")\n",
    "    \n",
    "    try:\n",
    "        # Remove .txt extension and extract number\n",
    "        base_name = os.path.splitext(filename)[0]  # Remove .txt\n",
    "        number = ''.join(filter(str.isdigit, base_name))  # Extract just the numbers\n",
    "        \n",
    "        if not number:\n",
    "            logger.warning(f\"No numeric ID found in filename: {filename}\")\n",
    "            return None\n",
    "            \n",
    "        formatted_id = f\"{prefix}{number}\"\n",
    "        logger.debug(f\"Extracted ID: {formatted_id}\")\n",
    "        return formatted_id\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting requirement ID from {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_requirements(source_dir, prefix, output_file, collection_id, collection_name, collection_desc):\n",
    "    \"\"\"Process all requirement files in a directory and create XML output.\"\"\"\n",
    "    logger.info(f\"Processing requirements from directory: {source_dir}\")\n",
    "    logger.info(f\"Creating output file: {output_file}\")\n",
    "    \n",
    "    # Create XML structure\n",
    "    root = create_xml_structure(collection_id, collection_name, collection_desc)\n",
    "    artifacts_elem = root.find(\"artifacts\")\n",
    "    \n",
    "    try:\n",
    "        # Process each file in the directory\n",
    "        for filename in sorted(os.listdir(source_dir)):\n",
    "            if filename.endswith('.txt'):\n",
    "                filepath = os.path.join(source_dir, filename)\n",
    "                logger.debug(f\"Processing file: {filepath}\")\n",
    "                \n",
    "                # Extract requirement ID with prefix\n",
    "                req_id = extract_requirement_id(filename, prefix)\n",
    "                if not req_id:\n",
    "                    logger.warning(f\"Skipping file due to invalid ID format: {filepath}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process the file\n",
    "                content = process_requirement_file(filepath)\n",
    "                if content:\n",
    "                    add_artifact(artifacts_elem, req_id, content)\n",
    "                else:\n",
    "                    logger.warning(f\"Skipping file due to processing error: {filepath}\")\n",
    "        \n",
    "        # Generate and validate XML\n",
    "        xml_string = prettify_xml(root)\n",
    "        \n",
    "        if validate_xml(('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n' + xml_string).encode('utf-8')):\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                f.write(xml_string)\n",
    "            \n",
    "            logger.info(f\"Successfully created XML file: {output_file}\")\n",
    "        else:\n",
    "            logger.error(\"XML validation failed, file not written\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing requirements: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Starting requirements processing\")\n",
    "    \n",
    "    # Process use cases (UC)\n",
    "    process_requirements(\n",
    "        source_dir=\"./uc\",\n",
    "        prefix=\"UC\",\n",
    "        output_file=\"eANCI-comments-functions-sourceArtifacts.xml\",\n",
    "        collection_id=\"UC\",\n",
    "        collection_name=\"eANCI Source Artifacts\",\n",
    "        collection_desc=\"Use cases\"\n",
    "    )\n",
    "    \n",
    "    # Process class codes (CC)\n",
    "    process_requirements(\n",
    "        source_dir=\"./cc\",\n",
    "        prefix=\"CC\",\n",
    "        output_file=\"eANCI-comments-functions-targetArtifacts.xml\",\n",
    "        collection_id=\"CC\",\n",
    "        collection_name=\"eANCI Target Artifacts\",\n",
    "        collection_desc=\"Class code\"\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Requirements processing completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
