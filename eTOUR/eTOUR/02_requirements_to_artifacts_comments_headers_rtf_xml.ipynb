{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "import re\n",
    "import unicodedata\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "# Get the actual project root by going up to the main project directory\n",
    "notebook_path = Path.cwd()  # Current working directory (notebook location)\n",
    "project_root = notebook_path.parent.parent.parent  # Go up 3 levels to reach project root\n",
    "src_path = project_root / 'src'\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.append(str(src_path))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"requirements_processor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Utility Classes and Functions\n",
    "\n",
    "class DebugTimer:\n",
    "    \"\"\"\n",
    "    Utility class for timing code execution and logging checkpoints\n",
    "    \n",
    "    Args:\n",
    "        name: Name of the timer for logging\n",
    "        logger: Logger instance to use\n",
    "    \"\"\"\n",
    "    def __init__(self, name, logger):\n",
    "        self.name = name\n",
    "        self.logger = logger\n",
    "        self.start_time = datetime.now()\n",
    "        self.last_checkpoint = self.start_time\n",
    "        self.logger.debug(f\"Started timer '{self.name}'\")\n",
    "        \n",
    "    def checkpoint(self, message):\n",
    "        \"\"\"Log time since last checkpoint\"\"\"\n",
    "        now = datetime.now()\n",
    "        elapsed = now - self.last_checkpoint\n",
    "        self.logger.debug(f\"[{self.name}] {message} - {elapsed.total_seconds():.3f}s\")\n",
    "        self.last_checkpoint = now\n",
    "        \n",
    "    def end(self):\n",
    "        \"\"\"Log total execution time and end timer\"\"\"\n",
    "        now = datetime.now()\n",
    "        total = now - self.start_time\n",
    "        self.logger.debug(f\"[{self.name}] Total execution time: {total.total_seconds():.3f}s\")\n",
    "\n",
    "def handle_exception(func):\n",
    "    \"\"\"\n",
    "    Decorator to handle exceptions in functions\n",
    "    \n",
    "    Args:\n",
    "        func: Function to wrap with exception handling\n",
    "    \n",
    "    Returns:\n",
    "        Wrapped function with exception handling\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Exception in {func.__name__}: {str(e)}\")\n",
    "            logger.debug(traceback.format_exc())\n",
    "            # Re-raise the exception after logging\n",
    "            raise\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Content Processing Functions\n",
    "\n",
    "def sanitize_content(content):\n",
    "    \"\"\"\n",
    "    Sanitize content to ensure XML/JSON compatibility.\n",
    "    Replace or remove problematic characters while preserving meaningful whitespace.\n",
    "    \n",
    "    Args:\n",
    "        content: String to sanitize\n",
    "        \n",
    "    Returns:\n",
    "        Sanitized string\n",
    "    \"\"\"\n",
    "    logger.debug(\"Sanitizing content\")\n",
    "    \n",
    "    # First, handle the specific problematic character that appears as a box with a question mark\n",
    "    # This is likely the Unicode character U+00B7 (middle dot) or similar\n",
    "    # We'll replace all non-ASCII characters with appropriate substitutions\n",
    "    \n",
    "    # Define common replacements for specific Unicode characters\n",
    "    replacements = {\n",
    "        '\\u2018': \"'\",  # Left single quote\n",
    "        '\\u2019': \"'\",  # Right single quote\n",
    "        '\\u201C': '\"',  # Left double quote\n",
    "        '\\u201D': '\"',  # Right double quote\n",
    "        '\\u2013': '-',  # En dash\n",
    "        '\\u2014': '--', # Em dash\n",
    "        '\\u2026': '...', # Ellipsis\n",
    "        '\\u00A0': ' ',  # Non-breaking space\n",
    "        '\\u00B7': '-',  # Middle dot - changed to hyphen\n",
    "        '\\u2022': '-',  # Bullet - changed to hyphen\n",
    "        '\\u2212': '-',  # Minus sign\n",
    "        '\\u00AD': '-',  # Soft hyphen\n",
    "        '\\u2010': '-',  # Hyphen\n",
    "        '\\u2011': '-',  # Non-breaking hyphen\n",
    "        '\\u00B0': ' degrees', # Degree sign\n",
    "        '\\u00AE': '(R)', # Registered trademark\n",
    "        '\\u00A9': '(C)', # Copyright\n",
    "        '\\u00A7': 'Section ', # Section sign\n",
    "        '\\u00A6': '|',   # Broken bar\n",
    "        '\\u00A5': 'Yen', # Yen sign\n",
    "        '\\u00A4': '$',   # Currency sign\n",
    "        '\\u00A3': 'GBP', # Pound sign\n",
    "        '\\u00A2': 'c',   # Cent sign\n",
    "        '\\u00A1': '!',   # Inverted exclamation mark\n",
    "        '\\u00BF': '?'    # Inverted question mark\n",
    "    }\n",
    "    \n",
    "    # Apply specific replacements\n",
    "    for old, new in replacements.items():\n",
    "        content = content.replace(old, new)\n",
    "    \n",
    "    # Handle the problematic character that appears as a box with a question mark\n",
    "    # This is likely to be a character like the bullet point (•) or similar\n",
    "    # First, try to identify and replace common problematic characters\n",
    "    \n",
    "    # Replace all bullet-like characters with hyphens\n",
    "    content = re.sub(r'[•·‣⁃⦁◦◘◙■□▪▫▬▭▮▯]', '-', content)\n",
    "    \n",
    "    # Replace all other non-ASCII characters that might cause issues\n",
    "    # This is a more aggressive approach but ensures all problematic characters are handled\n",
    "    sanitized = \"\"\n",
    "    for char in content:\n",
    "        if ord(char) < 128:  # ASCII characters\n",
    "            sanitized += char\n",
    "        elif char in replacements:\n",
    "            sanitized += replacements[char]\n",
    "        elif ord(char) == 0xFFFD:  # Replacement character (�)\n",
    "            sanitized += '-'\n",
    "        elif unicodedata.category(char).startswith('P'):  # Punctuation\n",
    "            sanitized += '-'\n",
    "        elif unicodedata.category(char).startswith('S'):  # Symbols\n",
    "            sanitized += '-'\n",
    "        elif unicodedata.category(char).startswith('Z'):  # Separators\n",
    "            sanitized += ' '\n",
    "        else:\n",
    "            sanitized += '-'  # Replace all other non-ASCII with hyphen\n",
    "    \n",
    "    # Clean up the text\n",
    "    # Remove multiple spaces while preserving newlines\n",
    "    sanitized = re.sub(r' +', ' ', sanitized)\n",
    "    sanitized = re.sub(r'\\n +', '\\n', sanitized)\n",
    "    \n",
    "    # Clean up multiple hyphens\n",
    "    sanitized = re.sub(r'-+', '-', sanitized)\n",
    "    \n",
    "    # Clean up empty lines while preserving paragraph structure\n",
    "    sanitized = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', sanitized)\n",
    "    \n",
    "    logger.debug(\"Content sanitization completed\")\n",
    "    return sanitized.strip()\n",
    "\n",
    "def strip_rtf(content):\n",
    "    \"\"\"\n",
    "    Strip RTF formatting from text while preserving the actual content.\n",
    "    \n",
    "    Args:\n",
    "        content: String potentially containing RTF formatting\n",
    "        \n",
    "    Returns:\n",
    "        Plain text with RTF formatting removed\n",
    "    \"\"\"\n",
    "    logger.debug(\"Stripping RTF formatting\")\n",
    "    \n",
    "    # Check if content appears to be RTF\n",
    "    if not content.startswith('{\\\\rtf'):\n",
    "        return content\n",
    "        \n",
    "    # Remove RTF control words and groups\n",
    "    def strip_rtf_controls(text):\n",
    "        # Remove RTF headers and groups\n",
    "        text = re.sub(r'^{\\\\rtf[^}]*}', '', text)\n",
    "        # Remove other RTF groups\n",
    "        text = re.sub(r'{[^{}]*}', '', text)\n",
    "        # Remove RTF control words (starting with backslash)\n",
    "        text = re.sub(r'\\\\[a-z]+[-]?[0-9]*\\s?', '', text)\n",
    "        # Remove special characters - fixed the syntax error here\n",
    "        text = re.sub(r'\\\\~|\\\\-|\\\\\\\\|\\\\:|\\\\<|\\\\>|\\\\{|\\\\}|\\\\\\'[0-9a-f]{2}', '', text)\n",
    "        return text\n",
    "    \n",
    "    # Strip RTF formatting\n",
    "    plain_text = strip_rtf_controls(content)\n",
    "    \n",
    "    # Clean up the resulting text\n",
    "    plain_text = re.sub(r'\\s+', ' ', plain_text)  # Normalize whitespace\n",
    "    plain_text = plain_text.strip()\n",
    "    \n",
    "    logger.debug(\"RTF formatting stripped successfully\")\n",
    "    return plain_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: XML Structure Functions\n",
    "\n",
    "def create_xml_structure(collection_id, name, description):\n",
    "    \"\"\"\n",
    "    Create the basic XML structure for artifacts collection.\n",
    "    \n",
    "    Args:\n",
    "        collection_id: ID for the collection\n",
    "        name: Name of the collection\n",
    "        description: Description of the collection\n",
    "        \n",
    "    Returns:\n",
    "        XML Element representing the root of the structure\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Creating XML structure for collection: {collection_id}\")\n",
    "    \n",
    "    root = ET.Element(\"artifacts_collection\")\n",
    "    \n",
    "    # Add collection info\n",
    "    collection_info = ET.SubElement(root, \"collection_info\")\n",
    "    id_elem = ET.SubElement(collection_info, \"id\")\n",
    "    id_elem.text = collection_id\n",
    "    name_elem = ET.SubElement(collection_info, \"name\")\n",
    "    name_elem.text = name\n",
    "    version_elem = ET.SubElement(collection_info, \"version\")\n",
    "    version_elem.text = \"1.1\"\n",
    "    desc_elem = ET.SubElement(collection_info, \"description\")\n",
    "    desc_elem.text = description\n",
    "    \n",
    "    # Add artifacts container\n",
    "    artifacts = ET.SubElement(root, \"artifacts\")\n",
    "    \n",
    "    return root\n",
    "\n",
    "def add_artifact(artifacts_elem, req_id, content):\n",
    "    \"\"\"\n",
    "    Add an artifact to the artifacts element.\n",
    "    \n",
    "    Args:\n",
    "        artifacts_elem: XML element to add artifact to\n",
    "        req_id: ID for the artifact\n",
    "        content: Content of the artifact\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Adding artifact with ID: {req_id}\")\n",
    "    \n",
    "    try:\n",
    "        artifact = ET.SubElement(artifacts_elem, \"artifact\")\n",
    "        \n",
    "        id_elem = ET.SubElement(artifact, \"id\")\n",
    "        id_elem.text = req_id\n",
    "        \n",
    "        content_elem = ET.SubElement(artifact, \"content\")\n",
    "        content_elem.text = content\n",
    "        \n",
    "        parent_id = ET.SubElement(artifact, \"parent_id\")\n",
    "        \n",
    "        logger.debug(f\"Successfully added artifact: {req_id}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error adding artifact {req_id}: {e}\")\n",
    "        raise\n",
    "\n",
    "def validate_xml(xml_string):\n",
    "    \"\"\"\n",
    "    Validate that the XML is well-formed.\n",
    "    \n",
    "    Args:\n",
    "        xml_string: XML string to validate\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating if XML is valid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ET.fromstring(xml_string)\n",
    "        return True\n",
    "    except ET.ParseError as e:\n",
    "        logger.error(f\"XML validation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def prettify_xml(elem):\n",
    "    \"\"\"\n",
    "    Return a pretty-printed XML string for the Element.\n",
    "    \n",
    "    Args:\n",
    "        elem: XML Element to prettify\n",
    "        \n",
    "    Returns:\n",
    "        Pretty-printed XML string\n",
    "    \"\"\"\n",
    "    rough_string = ET.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    # Skip the XML declaration since we'll add it manually\n",
    "    pretty_xml = reparsed.toprettyxml(indent=\"  \")\n",
    "    # Remove the first line containing the XML declaration\n",
    "    return '\\n'.join(pretty_xml.split('\\n')[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Java Code Extraction Function\n",
    "\n",
    "@handle_exception\n",
    "def extract_java_headers_and_comments(content):\n",
    "    \"\"\"\n",
    "    Extract only imports, comments, and method/class declarations from Java-like content\n",
    "    without including any implementation details.\n",
    "    \n",
    "    Args:\n",
    "        content: String containing Java code\n",
    "        \n",
    "    Returns:\n",
    "        String containing extracted imports, comments, and declarations only\n",
    "    \"\"\"\n",
    "    timer = DebugTimer(\"java_extraction\", logger)\n",
    "    logger.debug(\"Starting Java headers and comments extraction\")\n",
    "\n",
    "    # Normalize comment spacing issues (fix spaces in comment markers)\n",
    "    content = re.sub(r'/\\s*\\*\\s*\\*', '/**', content)\n",
    "    content = re.sub(r'\\*\\s*/', '*/', content)\n",
    "    content = re.sub(r'/\\s*/', '//', content)\n",
    "    \n",
    "    # Extract package declaration\n",
    "    package_match = re.search(r'package\\s+[^;]+;', content)\n",
    "    package_line = package_match.group(0) if package_match else \"\"\n",
    "    \n",
    "    # Extract import statements\n",
    "    import_pattern = re.compile(r'import\\s+[^;]+;', re.MULTILINE)\n",
    "    imports = import_pattern.findall(content)\n",
    "    \n",
    "    # Extract class declaration with inheritance (without implementation)\n",
    "    class_pattern = re.compile(r'(public|private|protected)?\\s*class\\s+\\w+(\\s+extends\\s+\\w+)?(\\s+implements\\s+[^{(]+)?', re.MULTILINE)\n",
    "    class_match = class_pattern.search(content)\n",
    "    class_declaration = class_match.group(0) if class_match else \"\"\n",
    "    \n",
    "    # Extract interface declaration (without implementation)\n",
    "    interface_pattern = re.compile(r'(public|private|protected)?\\s*interface\\s+\\w+(\\s+extends\\s+[^{(]+)?', re.MULTILINE)\n",
    "    interface_match = interface_pattern.search(content)\n",
    "    interface_declaration = interface_match.group(0) if interface_match else \"\"\n",
    "    \n",
    "    # Extract method signatures with their comments, but without implementation\n",
    "    method_pattern = re.compile(\n",
    "        r'(/\\*\\*[\\s\\S]*?\\*/\\s*)?'  # Optional block comment\n",
    "        r'(public|private|protected)(\\s+static)?\\s+'  # Access modifier\n",
    "        r'[\\w<>[\\],\\s]+\\s+'  # Return type\n",
    "        r'(\\w+)\\s*'  # Method name\n",
    "        r'\\([^)]*\\)'  # Parameters\n",
    "        r'(\\s+throws\\s+[\\w,\\s]+)?',  # Optional throws clause\n",
    "        re.DOTALL\n",
    "    )\n",
    "    \n",
    "    methods = []\n",
    "    for method_match in method_pattern.finditer(content):\n",
    "        # If there's a comment, include it\n",
    "        comment = method_match.group(1) or \"\"\n",
    "        \n",
    "        # Get just the method signature (no implementation)\n",
    "        signature = method_match.group(0)[len(comment):].strip()\n",
    "        \n",
    "        # Add to methods list\n",
    "        if comment:\n",
    "            methods.append(f\"{comment}\\n{signature}\")\n",
    "        else:\n",
    "            methods.append(signature)\n",
    "    \n",
    "    # Extract all block comments that might not be associated with methods\n",
    "    block_comment_pattern = re.compile(r'/\\*\\*[\\s\\S]*?\\*/', re.DOTALL)\n",
    "    block_comments = []\n",
    "    \n",
    "    for comment_match in block_comment_pattern.finditer(content):\n",
    "        comment = comment_match.group(0)\n",
    "        # Only add if not already part of a method\n",
    "        if not any(comment in method for method in methods):\n",
    "            block_comments.append(comment)\n",
    "    \n",
    "    # Extract all line comments\n",
    "    line_comment_pattern = re.compile(r'//.*$', re.MULTILINE)\n",
    "    line_comments = []\n",
    "    \n",
    "    for line_match in line_comment_pattern.finditer(content):\n",
    "        line = line_match.group(0)\n",
    "        line_comments.append(line)\n",
    "    \n",
    "    # Combine all extracted elements\n",
    "    extracted_parts = []\n",
    "    \n",
    "    if package_line:\n",
    "        extracted_parts.append(package_line)\n",
    "    \n",
    "    if imports:\n",
    "        extracted_parts.append(\"\\n\".join(imports))\n",
    "    \n",
    "    # Add class or interface declaration (without implementation)\n",
    "    if class_declaration:\n",
    "        extracted_parts.append(class_declaration)\n",
    "    elif interface_declaration:\n",
    "        extracted_parts.append(interface_declaration)\n",
    "    \n",
    "    # Add methods (signatures only, no implementation)\n",
    "    if methods:\n",
    "        extracted_parts.append(\"\\n\\n\".join(methods))\n",
    "    \n",
    "    # Add block comments that weren't already included\n",
    "    if block_comments:\n",
    "        extracted_parts.append(\"\\n\\n\".join(block_comments))\n",
    "    \n",
    "    # Add line comments that weren't already included\n",
    "    if line_comments:\n",
    "        extracted_parts.append(\"\\n\".join(line_comments))\n",
    "    \n",
    "    timer.checkpoint(\"Finished extraction\")\n",
    "    result = \"\\n\\n\".join(extracted_parts)\n",
    "    timer.end()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: File Processing Functions\n",
    "\n",
    "@handle_exception\n",
    "def process_requirement_file(filepath):\n",
    "    \"\"\"\n",
    "    Process a single requirement file and extract its content.\n",
    "    For Java-like content (in CC directory), only extract comments, headers, and dependencies.\n",
    "    For RTF content, strip the formatting.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the requirement file\n",
    "        \n",
    "    Returns:\n",
    "        Sanitized content from the file\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Processing requirement file: {filepath}\")\n",
    "    \n",
    "    # First try UTF-8 with error handling\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8', errors='replace') as file:\n",
    "            content = file.read().strip()\n",
    "            if '\\ufffd' in content:  # Replacement character indicating encoding issues\n",
    "                raise UnicodeDecodeError('utf-8', b'', 0, 1, 'invalid start byte')\n",
    "            \n",
    "            # Check if this is likely Java code\n",
    "            java_indicators = ['package ', 'import ', 'public class', 'private class', 'protected class']\n",
    "            is_java = any(indicator in content for indicator in java_indicators)\n",
    "            \n",
    "            if is_java:\n",
    "                logger.debug(f\"Detected Java-like content in {filepath}\")\n",
    "                content = extract_java_headers_and_comments(content)\n",
    "            else:\n",
    "                # Check for and strip RTF formatting\n",
    "                content = strip_rtf(content)\n",
    "            \n",
    "            return sanitize_content(content)\n",
    "            \n",
    "    except UnicodeDecodeError:\n",
    "        # Only log warning once per directory\n",
    "        dir_path = os.path.dirname(filepath)\n",
    "        if not hasattr(process_requirement_file, '_warned_dirs'):\n",
    "            process_requirement_file._warned_dirs = set()\n",
    "        if dir_path not in process_requirement_file._warned_dirs:\n",
    "            logger.warning(f\"Files in {dir_path} appear to use latin-1 encoding instead of UTF-8\")\n",
    "            process_requirement_file._warned_dirs.add(dir_path)\n",
    "            \n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='latin-1') as file:\n",
    "                content = file.read().strip()\n",
    "                \n",
    "                # Check for Java content with latin-1 encoding\n",
    "                java_indicators = ['package ', 'import ', 'public class', 'private class', 'protected class']\n",
    "                is_java = any(indicator in content for indicator in java_indicators)\n",
    "                \n",
    "                if is_java:\n",
    "                    logger.debug(f\"Detected Java-like content in {filepath}\")\n",
    "                    content = extract_java_headers_and_comments(content)\n",
    "                else:\n",
    "                    # Check for and strip RTF formatting\n",
    "                    content = strip_rtf(content)\n",
    "                    \n",
    "                return sanitize_content(content)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading file {filepath} with latin-1 encoding: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {filepath}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_requirement_id(filename, prefix):\n",
    "    \"\"\"\n",
    "    Extract the requirement ID from filename and add appropriate prefix.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): The filename to process (e.g. 'UC1.txt' or 'Banner.txt')\n",
    "        prefix (str): The prefix to add ('UC' or 'CC')\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted ID (e.g. 'UC1' or 'CC_Banner')\n",
    "    \"\"\"\n",
    "    logger.debug(f\"Extracting requirement ID from filename: {filename} with prefix: {prefix}\")\n",
    "    \n",
    "    try:\n",
    "        # Remove .txt extension\n",
    "        base_name = os.path.splitext(filename)[0]  # Remove .txt\n",
    "        \n",
    "        # For UC files, extract just the numbers\n",
    "        if prefix == \"UC\":\n",
    "            number = ''.join(filter(str.isdigit, base_name))\n",
    "            if not number:\n",
    "                logger.warning(f\"No numeric ID found in filename: {filename}\")\n",
    "                return None\n",
    "            formatted_id = f\"{prefix}{number}\"\n",
    "        # For CC files, use the whole base name with an underscore\n",
    "        else:\n",
    "            formatted_id = f\"{prefix}_{base_name}\"\n",
    "            \n",
    "        logger.debug(f\"Extracted ID: {formatted_id}\")\n",
    "        return formatted_id\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting requirement ID from {filename}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Main Processing Functions\n",
    "\n",
    "@handle_exception\n",
    "def process_requirements(source_dir, prefix, output_file, collection_id, collection_name, collection_desc):\n",
    "    \"\"\"\n",
    "    Process all requirement files in a directory and create XML output.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Directory containing requirement files\n",
    "        prefix: Prefix for requirement IDs\n",
    "        output_file: Output file path\n",
    "        collection_id: ID for the collection\n",
    "        collection_name: Name of the collection\n",
    "        collection_desc: Description of the collection\n",
    "    \"\"\"\n",
    "    logger.info(f\"Processing requirements from directory: {source_dir}\")\n",
    "    logger.info(f\"Creating output file: {output_file}\")\n",
    "    \n",
    "    # Create XML structure\n",
    "    root = create_xml_structure(collection_id, collection_name, collection_desc)\n",
    "    artifacts_elem = root.find(\"artifacts\")\n",
    "    \n",
    "    try:\n",
    "        # Process each file in the directory\n",
    "        for filename in sorted(os.listdir(source_dir)):\n",
    "            if filename.endswith('.txt') or filename.endswith('.TXT'):\n",
    "                filepath = os.path.join(source_dir, filename)\n",
    "                logger.debug(f\"Processing file: {filepath}\")\n",
    "                \n",
    "                # Extract requirement ID with prefix\n",
    "                req_id = extract_requirement_id(filename, prefix)\n",
    "                if not req_id:\n",
    "                    logger.warning(f\"Skipping file due to invalid ID format: {filepath}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process the file\n",
    "                content = process_requirement_file(filepath)\n",
    "                if content:\n",
    "                    add_artifact(artifacts_elem, req_id, content)\n",
    "                else:\n",
    "                    logger.warning(f\"Skipping file due to processing error: {filepath}\")\n",
    "        \n",
    "        # Generate and validate XML\n",
    "        xml_string = prettify_xml(root)\n",
    "        \n",
    "        if validate_xml(('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n' + xml_string).encode('utf-8')):\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                f.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n')\n",
    "                f.write(xml_string)\n",
    "            \n",
    "            logger.info(f\"Successfully created XML file: {output_file}\")\n",
    "        else:\n",
    "            logger.error(\"XML validation failed, file not written\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing requirements: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process requirements and generate XML files\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting requirements processing\")\n",
    "    \n",
    "    # Process use cases (UC)\n",
    "    process_requirements(\n",
    "        source_dir=\"./UC\",\n",
    "        prefix=\"UC\",\n",
    "        output_file=\"eTOUR-comments-functions-sourceArtifacts.xml\",\n",
    "        collection_id=\"UC\",\n",
    "        collection_name=\"eTOUR Source Artifacts\",\n",
    "        collection_desc=\"Use cases\"\n",
    "    )\n",
    "    \n",
    "    # Process class codes (CC)\n",
    "    process_requirements(\n",
    "        source_dir=\"./CC\",\n",
    "        prefix=\"CC\",\n",
    "        output_file=\"eTOUR-comments-functions-targetArtifacts.xml\",\n",
    "        collection_id=\"CC\",\n",
    "        collection_name=\"eTOUR Target Artifacts\",\n",
    "        collection_desc=\"Class code headers and comments\"\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Requirements processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Execution Cell\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
