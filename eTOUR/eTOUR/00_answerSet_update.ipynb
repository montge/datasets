{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: eTOUR/eTOUR/00_answerSet_update.ipynb\n",
    "# Imports and Setup\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger('answer_set_updater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def handle_exception(func):\n",
    "    \"\"\"\n",
    "    Decorator to handle exceptions in functions.\n",
    "    \n",
    "    Args:\n",
    "        func: The function to wrap with exception handling\n",
    "        \n",
    "    Returns:\n",
    "        The wrapped function with exception handling\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "def get_cc_mapping():\n",
    "    \"\"\"\n",
    "    Create a mapping from numeric CC IDs to filename-based CC IDs.\n",
    "    Scans the CC directory to build the mapping.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping from numeric IDs to filename-based IDs\n",
    "    \"\"\"\n",
    "    logger.info(\"Building CC ID mapping\")\n",
    "    cc_mapping = {}\n",
    "    \n",
    "    try:\n",
    "        cc_dir = \"./CC\"\n",
    "        if not os.path.exists(cc_dir):\n",
    "            logger.warning(f\"CC directory not found: {cc_dir}\")\n",
    "            return cc_mapping\n",
    "            \n",
    "        # Get all CC files\n",
    "        cc_files = sorted([f for f in os.listdir(cc_dir) if f.lower().endswith('.txt')])\n",
    "        \n",
    "        # Create mapping from index to filename\n",
    "        for i, filename in enumerate(cc_files, 1):\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            cc_mapping[f\"CC{i}\"] = f\"CC_{base_name}\"\n",
    "            logger.debug(f\"Mapped CC{i} to CC_{base_name}\")\n",
    "            \n",
    "        logger.info(f\"Created mapping for {len(cc_mapping)} CC files\")\n",
    "        return cc_mapping\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error building CC mapping: {str(e)}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Updated Content Sanitization Functions with Special Character Fix\n",
    "\n",
    "def sanitize_content(content):\n",
    "    \"\"\"\n",
    "    Sanitize content to ensure XML/JSON compatibility.\n",
    "    \n",
    "    Args:\n",
    "        content (str): The raw text content to sanitize\n",
    "        \n",
    "    Returns:\n",
    "        str: Sanitized content with problematic characters replaced\n",
    "    \"\"\"\n",
    "    logger.debug(\"Sanitizing content\")\n",
    "    \n",
    "    # Define the XML 1.0 specification valid characters\n",
    "    # Valid ranges are:\n",
    "    # tab, newline, carriage return (0x9, 0xA, 0xD)\n",
    "    # ASCII characters (0x20-0x7E)\n",
    "    # Extended ASCII and Unicode (0x7F-0xFFFD)\n",
    "    # Excluding surrogate blocks (0xFDD0-0xFDEF)\n",
    "    \n",
    "    # First, replace common problematic characters\n",
    "    replacements = {\n",
    "        '\\u2018': \"'\",  # Left single quote\n",
    "        '\\u2019': \"'\",  # Right single quote\n",
    "        '\\u201C': '\"',  # Left double quote\n",
    "        '\\u201D': '\"',  # Right double quote\n",
    "        '\\u2013': '-',  # En dash\n",
    "        '\\u2014': '--', # Em dash\n",
    "        '\\u2026': '...', # Ellipsis\n",
    "        '\\u00B7': '-',  # Middle dot/bullet point\n",
    "        '\\u2022': '-',  # Bullet point\n",
    "        '\\u00A0': ' ',  # Non-breaking space\n",
    "        '\\u00B0': ' ',  # Degree sign\n",
    "        '\\u00BA': ' ',  # Masculine ordinal indicator\n",
    "        '\\u00E8': 'e',  # è (e with grave)\n",
    "        '\\u00E9': 'e',  # é (e with acute)\n",
    "        '\\u00EC': 'i',  # ì (i with grave)\n",
    "        '\\u00F2': 'o',  # ò (o with grave)\n",
    "        '\\u00F9': 'u',  # ù (u with grave)\n",
    "        '\\u00BF': '?',  # Inverted question mark\n",
    "        '\\u00A1': '!',  # Inverted exclamation mark\n",
    "        # Add the problematic character from UC files\n",
    "        '\\u00B0': '-',  # Degree symbol that appears as � in the UC files\n",
    "        '\\u00B7': '-',  # Middle dot that appears as � in the UC files\n",
    "        '\\u2022': '-',  # Bullet that appears as � in the UC files\n",
    "        '\\u2023': '-',  # Triangular bullet that might appear as � in the UC files\n",
    "        '\\u25E6': '-',  # White bullet that might appear as � in the UC files\n",
    "        '\\u2043': '-',  # Hyphen bullet that might appear as � in the UC files\n",
    "        '\\u204C': '-',  # Black leftwards bullet that might appear as � in the UC files\n",
    "        '\\u204D': '-',  # Black rightwards bullet that might appear as � in the UC files\n",
    "        '\\u2219': '-',  # Bullet operator that might appear as � in the UC files\n",
    "        '\\u25D8': '-',  # Inverse bullet that might appear as � in the UC files\n",
    "        '\\u25D9': '-',  # Inverse white circle that might appear as � in the UC files\n",
    "        '\\u25AA': '-',  # Black small square that might appear as � in the UC files\n",
    "        '\\u25AB': '-',  # White small square that might appear as � in the UC files\n",
    "        '\\u25FE': '-',  # Black medium small square that might appear as � in the UC files\n",
    "        '\\u25FD': '-',  # White medium small square that might appear as � in the UC files\n",
    "        # Catch-all for any remaining � characters\n",
    "        '�': '-'        # Direct replacement for the � character\n",
    "    }\n",
    "    \n",
    "    for old, new in replacements.items():\n",
    "        content = content.replace(old, new)\n",
    "    \n",
    "    # Function to check if a character is valid XML\n",
    "    def is_valid_xml_char(char):\n",
    "        codepoint = ord(char)\n",
    "        return (\n",
    "            codepoint == 0x9 or\n",
    "            codepoint == 0xA or\n",
    "            codepoint == 0xD or\n",
    "            (0x20 <= codepoint <= 0x7E) or\n",
    "            (0x7F <= codepoint <= 0xFFFD and not (0xFDD0 <= codepoint <= 0xFDEF))\n",
    "        )\n",
    "    \n",
    "    # Replace invalid characters with space\n",
    "    sanitized = ''.join(char if is_valid_xml_char(char) else ' ' for char in content)\n",
    "    \n",
    "    # Remove multiple spaces while preserving newlines\n",
    "    sanitized = re.sub(r' +', ' ', sanitized)\n",
    "    sanitized = re.sub(r'\\n +', '\\n', sanitized)\n",
    "    \n",
    "    # Clean up empty lines while preserving paragraph structure\n",
    "    sanitized = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', sanitized)\n",
    "    \n",
    "    logger.debug(\"Content sanitization completed\")\n",
    "    return sanitized.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Transformation Function\n",
    "\n",
    "@handle_exception\n",
    "def transform_answer_set(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Transform the answer set XML file by:\n",
    "    1. Changing EA prefix to UC in source_artifact_id\n",
    "    2. Changing EA prefix to CC_[Filename] in target_artifact_id using mapping\n",
    "    3. Adding confidence score of 1 to each link\n",
    "    4. Ensuring all target IDs have CC_ prefix\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input XML file\n",
    "        output_file (str): Path to output XML file\n",
    "    \"\"\"\n",
    "    logger.info(f\"Transforming answer set from {input_file} to {output_file}\")\n",
    "    \n",
    "    # Get CC mapping from numeric IDs to filename-based IDs\n",
    "    cc_mapping = get_cc_mapping()\n",
    "    \n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(input_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Track statistics\n",
    "    total_links = 0\n",
    "    updated_sources = 0\n",
    "    updated_targets = 0\n",
    "    added_confidence = 0\n",
    "    \n",
    "    # Process each link element\n",
    "    for link in root.findall('.//link'):\n",
    "        total_links += 1\n",
    "        \n",
    "        # Get source and target elements\n",
    "        source = link.find('source_artifact_id')\n",
    "        target = link.find('target_artifact_id')\n",
    "        \n",
    "        # Replace EA with UC in source\n",
    "        if source is not None and source.text and source.text.startswith('EA'):\n",
    "            old_value = source.text\n",
    "            source.text = 'UC' + source.text[2:]\n",
    "            logger.debug(f\"Updated source: {old_value} -> {source.text}\")\n",
    "            updated_sources += 1\n",
    "            \n",
    "        # Replace EA with CC_[Filename] in target using mapping\n",
    "        if target is not None and target.text:\n",
    "            old_value = target.text\n",
    "            \n",
    "            # Case 1: If it starts with EA, convert to CC format\n",
    "            if target.text.startswith('EA'):\n",
    "                numeric_id = 'CC' + target.text[2:]  # Convert EA123 to CC123\n",
    "                \n",
    "                # Use mapping if available, otherwise keep numeric ID\n",
    "                if numeric_id in cc_mapping:\n",
    "                    target.text = cc_mapping[numeric_id]\n",
    "                    logger.debug(f\"Updated target with mapping: {old_value} -> {target.text}\")\n",
    "                else:\n",
    "                    target.text = numeric_id\n",
    "                    logger.debug(f\"Updated target without mapping: {old_value} -> {target.text}\")\n",
    "                \n",
    "                updated_targets += 1\n",
    "            \n",
    "            # Case 2: If it's already a class name but missing CC_ prefix\n",
    "            elif not target.text.startswith('CC_'):\n",
    "                # Add CC_ prefix to ensure consistency with target artifacts\n",
    "                target.text = f\"CC_{target.text}\"\n",
    "                logger.debug(f\"Added CC_ prefix to target: {old_value} -> {target.text}\")\n",
    "                updated_targets += 1\n",
    "        \n",
    "        # Add confidence score if it doesn't exist\n",
    "        if link.find('confidence_score') is None:\n",
    "            confidence = ET.SubElement(link, 'confidence_score')\n",
    "            confidence.text = '1'\n",
    "            added_confidence += 1\n",
    "    \n",
    "    # Write the modified XML to the output file\n",
    "    tree.write(output_file, encoding='utf-8', xml_declaration=True)\n",
    "    \n",
    "    # Log statistics\n",
    "    logger.info(f\"Processed {total_links} links\")\n",
    "    logger.info(f\"Updated {updated_sources} source IDs\")\n",
    "    logger.info(f\"Updated {updated_targets} target IDs\")\n",
    "    logger.info(f\"Added confidence score to {added_confidence} links\")\n",
    "    logger.info(f\"Successfully transformed XML and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Execution and Verification\n",
    "\n",
    "@handle_exception\n",
    "def verify_transformation(output_file):\n",
    "    \"\"\"\n",
    "    Verify the transformation by reading and displaying parts of the output file.\n",
    "    \n",
    "    Args:\n",
    "        output_file (str): Path to the transformed XML file\n",
    "    \"\"\"\n",
    "    logger.info(f\"Verifying transformation in {output_file}\")\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(output_file):\n",
    "        logger.error(f\"Output file not found: {output_file}\")\n",
    "        return\n",
    "    \n",
    "    # Read and display first few links\n",
    "    tree = ET.parse(output_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Get all links\n",
    "    links = root.findall('.//link')\n",
    "    \n",
    "    # Display statistics\n",
    "    logger.info(f\"Total links in transformed file: {len(links)}\")\n",
    "    \n",
    "    # Display first 5 links\n",
    "    print(\"\\nSample of transformed links:\")\n",
    "    for i, link in enumerate(links[:5]):\n",
    "        source = link.find('source_artifact_id').text\n",
    "        target = link.find('target_artifact_id').text\n",
    "        confidence = link.find('confidence_score').text\n",
    "        print(f\"Link {i+1}: {source} -> {target} (confidence: {confidence})\")\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file = 'answer_req_code.xml'\n",
    "output_file = 'eTOUR-answerSet.xml'\n",
    "\n",
    "# Execute the transformation\n",
    "transform_answer_set(input_file, output_file)\n",
    "\n",
    "# Verify the transformation\n",
    "verify_transformation(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Additional Validation (Optional)\n",
    "\n",
    "@handle_exception\n",
    "def validate_against_artifacts(answer_set_file, source_artifacts_file, target_artifacts_file):\n",
    "    \"\"\"\n",
    "    Validate that all IDs in the answer set exist in the source and target artifact files.\n",
    "    \n",
    "    Args:\n",
    "        answer_set_file (str): Path to the answer set XML file\n",
    "        source_artifacts_file (str): Path to the source artifacts XML file\n",
    "        target_artifacts_file (str): Path to the target artifacts XML file\n",
    "    \"\"\"\n",
    "    logger.info(\"Validating answer set against artifact files\")\n",
    "    \n",
    "    # Check if files exist\n",
    "    for file_path in [answer_set_file, source_artifacts_file, target_artifacts_file]:\n",
    "        if not os.path.exists(file_path):\n",
    "            logger.error(f\"File not found: {file_path}\")\n",
    "            return\n",
    "    \n",
    "    # Parse XML files\n",
    "    answer_tree = ET.parse(answer_set_file)\n",
    "    source_tree = ET.parse(source_artifacts_file)\n",
    "    target_tree = ET.parse(target_artifacts_file)\n",
    "    \n",
    "    # Get all artifact IDs\n",
    "    source_ids = set(elem.text for elem in source_tree.findall('.//artifact/id'))\n",
    "    target_ids = set(elem.text for elem in target_tree.findall('.//artifact/id'))\n",
    "    \n",
    "    # Get all IDs from answer set\n",
    "    answer_source_ids = set(elem.text for elem in answer_tree.findall('.//source_artifact_id'))\n",
    "    answer_target_ids = set(elem.text for elem in answer_tree.findall('.//target_artifact_id'))\n",
    "    \n",
    "    # Check for missing IDs\n",
    "    missing_source_ids = answer_source_ids - source_ids\n",
    "    missing_target_ids = answer_target_ids - target_ids\n",
    "    \n",
    "    # Report results\n",
    "    if missing_source_ids:\n",
    "        logger.warning(f\"Found {len(missing_source_ids)} source IDs in answer set that don't exist in source artifacts\")\n",
    "        for id in sorted(missing_source_ids)[:10]:  # Show first 10\n",
    "            logger.warning(f\"Missing source ID: {id}\")\n",
    "    else:\n",
    "        logger.info(\"All source IDs in answer set exist in source artifacts\")\n",
    "    \n",
    "    if missing_target_ids:\n",
    "        logger.warning(f\"Found {len(missing_target_ids)} target IDs in answer set that don't exist in target artifacts\")\n",
    "        for id in sorted(missing_target_ids)[:10]:  # Show first 10\n",
    "            logger.warning(f\"Missing target ID: {id}\")\n",
    "    else:\n",
    "        logger.info(\"All target IDs in answer set exist in target artifacts\")\n",
    "    \n",
    "    # Overall validation result\n",
    "    if not missing_source_ids and not missing_target_ids:\n",
    "        logger.info(\"Validation successful: All IDs in answer set exist in artifact files\")\n",
    "    else:\n",
    "        logger.warning(\"Validation found issues with IDs in answer set\")\n",
    "\n",
    "# Run validation if artifact files exist\n",
    "if os.path.exists('eTOUR-sourceArtifacts.xml') and os.path.exists('eTOUR-targetArtifacts.xml'):\n",
    "    validate_against_artifacts('eTOUR-answerSet.xml', 'eTOUR-sourceArtifacts.xml', 'eTOUR-targetArtifacts.xml')\n",
    "else:\n",
    "    logger.warning(\"Skipping validation: Artifact files not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Additional Fix for Target Artifacts (if needed)\n",
    "\n",
    "@handle_exception\n",
    "def fix_target_artifacts_format(target_artifacts_file):\n",
    "    \"\"\"\n",
    "    Fix the target artifacts XML file to ensure all IDs have the CC_ prefix.\n",
    "    This is a one-time fix in case the target artifacts were generated without proper prefixes.\n",
    "    \n",
    "    Args:\n",
    "        target_artifacts_file (str): Path to the target artifacts XML file\n",
    "    \"\"\"\n",
    "    logger.info(f\"Checking and fixing target artifacts format in {target_artifacts_file}\")\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(target_artifacts_file):\n",
    "        logger.error(f\"Target artifacts file not found: {target_artifacts_file}\")\n",
    "        return\n",
    "    \n",
    "    # Parse XML file\n",
    "    tree = ET.parse(target_artifacts_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Track changes\n",
    "    changes_made = 0\n",
    "    \n",
    "    # Process each artifact ID\n",
    "    for id_elem in root.findall('.//artifact/id'):\n",
    "        if id_elem.text and not id_elem.text.startswith('CC_'):\n",
    "            old_value = id_elem.text\n",
    "            id_elem.text = f\"CC_{old_value}\"\n",
    "            logger.debug(f\"Fixed artifact ID: {old_value} -> {id_elem.text}\")\n",
    "            changes_made += 1\n",
    "    \n",
    "    # Only write if changes were made\n",
    "    if changes_made > 0:\n",
    "        logger.info(f\"Fixed {changes_made} artifact IDs in target artifacts file\")\n",
    "        tree.write(target_artifacts_file, encoding='utf-8', xml_declaration=True)\n",
    "    else:\n",
    "        logger.info(\"No fixes needed in target artifacts file\")\n",
    "\n",
    "# Run the fix if target artifacts file exists\n",
    "if os.path.exists('eTOUR-targetArtifacts.xml'):\n",
    "    fix_target_artifacts_format('eTOUR-targetArtifacts.xml')\n",
    "else:\n",
    "    logger.warning(\"Target artifacts file not found, skipping fix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
